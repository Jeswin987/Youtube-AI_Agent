# ğŸ¬ YouTube Analysis Agent

An intelligent AI agent that autonomously analyzes YouTube videos, generating comprehensive summaries, timestamps, themes, and content breakdowns.

---

## âœ¨ Features

- **Smart Summaries** â€“ AI-generated summaries with dynamic length based on video duration (100â€“600 words)
- **Key Timestamps** â€“ Extracts 7 important moments throughout the video
- **Theme Identification** â€“ Identifies 3â€“5 main topics discussed
- **Content Breakdown** â€“ Structured analysis (Introduction, Main Content, Conclusion)
- **Autonomous Fallback** â€“ Works on videos with or without captions
- **Whisper Integration** â€“ Automatic speech-to-text transcription when captions are unavailable

---

## ğŸ¤– Agentic AI Capabilities

This isnâ€™t just a static app â€” itâ€™s an **autonomous AI agent** that:

- ğŸ§  **Makes Decisions** â€“ Chooses between captions and Whisper transcription
- âš™ï¸ **Adapts Strategy** â€“ Adjusts summary length based on video duration
- ğŸ” **Self-Corrects** â€“ Built-in fallback ensures reliable output
- ğŸª„ **Orchestrates Tools** â€“ Coordinates YouTube API, Whisper AI, and LLM services

---

## ğŸ—ï¸ Project Architecture


â”œâ”€â”€ config.py # Configuration and settings
â”œâ”€â”€ models.py # Data structures (VideoMetadata, VideoAnalysis)
â”œâ”€â”€ llm_provider.py # LLM integration (Google Gemini/Ollama/Groq)
â”œâ”€â”€ youtube_service.py # YouTube data extraction
â”œâ”€â”€ whisper_service.py # Audio transcription (OpenAI Whisper)
â”œâ”€â”€ analyzer.py # AI analysis logic
â”œâ”€â”€ agent.py # Main agent orchestrator
â”œâ”€â”€ main.py # CLI entry point
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # Documentation (this file)


---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- ffmpeg (for Whisper audio processing)

### Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/Jeswin987/Youtube-AI_Agent
   cd youtube-analysis-agent
pip install -r requirements.txt
Install ffmpeg:


Download from gyan.dev/ffmpeg/builds

Extract and add to PATH

Add your API key in config.py:

LLM_PROVIDER = "google"  # or "ollama"
GOOGLE_API_KEY = "your_api_key_here"


ğŸ‘‰ Get a free key from: https://aistudio.google.com/app/apikey

Run the app:

python main.py


Enter a YouTube URL when prompted, and the agent will automatically analyze the video.

ğŸ“º VIDEO ANALYSIS: Introduction to Machine Learning
â±ï¸ Duration: 18.3 minutes

ğŸ“‹ SUMMARY
This video provides a comprehensive introduction to machine learning...
[342 words]

â° KEY TIMESTAMPS
[00:00] Introduction to the course
[03:15] What is Machine Learning
[07:45] Types of ML algorithms
[12:30] Real-world applications
[16:45] Getting started with ML

ğŸ·ï¸ MAIN THEMES
1. Machine Learning Fundamentals
2. Supervised vs Unsupervised Learning
3. Practical Applications
4. Getting Started Resources

ğŸ“– CONTENT BREAKDOWN
**Introduction:** The video opens by explaining the growing importance...
**Main Content:** The presenter discusses three main types of machine learning...
**Conclusion:** The video concludes with practical advice for beginners...

ğŸ§  How It Works
Autonomous Workflow

Extract video ID from URL

Fetch metadata (title, duration, author)

Get transcript automatically:

Try YouTube captions (fast)

If unavailable â†’ use Whisper AI (fallback)

Analyze video content using LLM

Generate structured output (summary, timestamps, themes, breakdown)

Key Agentic Behaviors

Decision 1 â€“ Transcript Method

if captions_available:
    use_captions()
else:
    use_whisper()


Decision 2 â€“ Summary Length

if video_duration < 5:
    summary_length = "100-150 words"
elif video_duration < 20:
    summary_length = "300-400 words"


Decision 3 â€“ Error Recovery

try:
    parse_json_response()
except:
    try_alternative_method()

ğŸ› ï¸ Tech Stack

Language: Python 3.8+

AI/LLM: Google Gemini (Gemini 1.5 Flash)

Speech Recognition: OpenAI Whisper

YouTube API: YouTube Transcript API, yt-dlp

Data Handling: JSON, Regex, TextBlob

ğŸ“ˆ Performance
Metric	Description
â±ï¸ Processing Time	30â€“60 seconds per video
âœ… Success Rate	100% (works with or without captions)
ğŸ“¹ Video Length Supported	5 â€“ 60+ minutes
ğŸ’° Cost	Free (uses free API tiers)
âš™ï¸ Configuration

Edit config.py as needed:

LLM_PROVIDER = "google"  # Options: google, ollama, groq
DYNAMIC_WORD_COUNT_RULES = {
    5: "100-150",
    10: "200-300",
    20: "300-400",
    40: "400-500",
    999: "500-600"
}
MAX_TRANSCRIPT_LENGTH = 15000
TEMPERATURE = 0.7

ğŸ¯ Use Cases

ğŸ“ Students â€“ Quickly summarize lecture videos

ğŸ§‘â€ğŸ”¬ Researchers â€“ Analyze academic talks & interviews

ğŸ¥ Creators â€“ Generate timestamps & video descriptions

ğŸ§ Accessibility â€“ Create transcripts for videos without captions

ğŸ’¼ Professionals â€“ Extract insights from webinars and conferences

ğŸš§ Limitations

Currently supports English only

Whisper transcription can be slow for long videos

Summary quality depends on audio clarity

Internet connection required for API calls

ğŸ”® Future Enhancements

 ğŸŒ Multi-language support

 ğŸ“œ Batch processing for playlists

 â¤ï¸ Sentiment analysis

 ğŸ”‘ Keyword extraction

 ğŸ§¾ Export results to PDF/Markdown

ğŸ“ License

MIT License â€” feel free to use, modify, or share for personal and educational purposes.

ğŸ‘¤ Author

Jesvin Devasia

GitHub: @https://github.com/Jeswin987


ğŸ™ Acknowledgments

OpenAI Whisper
 for speech recognition

Google Gemini AI
 for text understanding

YouTube Transcript API
 for caption extraction

ğŸ“š Documentation

Architecture Guide
 (optional)

API Reference
 (optional)



